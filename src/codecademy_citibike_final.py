# -*- coding: utf-8 -*-
"""Codecademy Citibike Final

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D41Ed4RsDYdxFPYpuTYc6YnWbnvzKyhl
"""

# using Google Colab environment
from google.colab import drive
drive.mount('/content/drive')

import glob
import pandas as pd

# Calling Google Colab to access the folder in the Google Drive
folder_path = '/content/drive/MyDrive/bike-rental-starter-kit/data/JC-201*.csv'
citibike_files = glob.glob(folder_path)
dfs = [pd.read_csv(file) for file in citibike_files]

# concatenating 12 citibike data files into one
citibike_raw = pd.concat(dfs, ignore_index=True)

# reading in the weather data from the same folder
weather_raw = pd.read_csv('/content/drive/MyDrive/bike-rental-starter-kit/data/newark_airport_2016.csv')

citibike_raw.head()

weather_raw.head()

import numpy as np
import pandas as pd

def _haversine_km(lat1, lon1, lat2, lon2):
    """Haversine distance in kilometers."""
    R = 6371.0088
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2
    return 2 * R * np.arcsin(np.sqrt(a))


# ==== 1) Citibike cleaning ====
def clean_citibike(df_raw: pd.DataFrame) -> pd.DataFrame:
    df = df_raw.copy()

    # --- column renaming ---
    rename_map = {
        'Trip Duration': 'trip_duration_seconds',
        'Start Time': 'start_time',
        'Stop Time': 'stop_time',
        'Start Station ID': 'start_station_id',
        'Start Station Name': 'start_station_name',
        'Start Station Latitude': 'start_latitude',
        'Start Station Longitude': 'start_longitude',
        'End Station ID': 'end_station_id',
        'End Station Name': 'end_station_name',
        'End Station Latitude': 'end_latitude',
        'End Station Longitude': 'end_longitude',
        'Bike ID': 'bike_id',
        'User Type': 'user_type',
        'Birth Year': 'birth_year',
        'Gender': 'gender',
        'Trip Duration (minutes)': 'trip_duration_minutes',
        'Latitude Change': 'latitude_change',
        'Longitude Change': 'longitude_change',
    }
    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})

    # --- dtypes & derived duration ---
    # times
    if 'start_time' in df: df['start_time'] = pd.to_datetime(df['start_time'])
    if 'stop_time' in df:  df['stop_time']  = pd.to_datetime(df['stop_time'])

    # numeric fields (coerce errors to NaN)
    num_cols = [
        'trip_duration_seconds','start_station_id','end_station_id','bike_id',
        'start_latitude','start_longitude','end_latitude','end_longitude',
        'birth_year','gender'
    ]
    for c in num_cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors='coerce')

    # minutes
    if 'trip_duration_minutes' not in df.columns and 'trip_duration_seconds' in df.columns:
        df['trip_duration_minutes'] = df['trip_duration_seconds'] / 60.0

    # --- gender mapping (1->M, 2->F, 0/NaN->NaN) ---
    if 'gender' in df.columns:
        df['gender'] = df['gender'].replace({1: 'M', 2: 'F', 0: pd.NA})

    # --- reasonable trip duration filter (1 min .. 24 hours) ---
    if 'trip_duration_minutes' in df.columns:
        df = df[(df['trip_duration_minutes'] >= 1) & (df['trip_duration_minutes'] <= 24*60)]

    # --- tighten lat/long bounds to NYC-area  ---
    LAT_MIN, LAT_MAX = 40.3, 41.2
    LON_MIN, LON_MAX = -74.5, -73.3
    for col in ['start_latitude','end_latitude']:
        if col in df.columns:
            df = df[df[col].between(LAT_MIN, LAT_MAX)]
    for col in ['start_longitude','end_longitude']:
        if col in df.columns:
            df = df[df[col].between(LON_MIN, LON_MAX)]

    # --- station name canonicalization (trim, de-dup spaces, Title Case) ---
    for col in ['start_station_name', 'end_station_name']:
        if col in df.columns:
            df[col] = (
                df[col].astype('string')
                      .str.strip()
                      .str.replace(r'\s+', ' ', regex=True)
                      .str.title()
            )

    # --- age (10..100; else NaN) ---
    if {'birth_year','start_time'}.issubset(df.columns):
        current_year = pd.Timestamp(df['start_time'].max()).year
        df['age'] = current_year - df['birth_year']
        df.loc[(df['age'] < 10) | (df['age'] > 100), 'age'] = np.nan

    # --- distance (km) & speed (km/h) & sanity filters you used ---
    if {'start_latitude','start_longitude','end_latitude','end_longitude'}.issubset(df.columns):
        df['distance_km'] = _haversine_km(
            df['start_latitude'], df['start_longitude'],
            df['end_latitude'],   df['end_longitude']
        )

    if {'distance_km','trip_duration_minutes'}.issubset(df.columns):
        duration_hours = (df['trip_duration_minutes'] / 60.0).replace(0, np.nan)
        df['speed_kmh'] = df['distance_km'] / duration_hours

        # Filter out impossible speeds (> 60 km/h) and long-duration zero-distance trips
        df = df[
            (df['speed_kmh'] <= 60) &
            ~((df['distance_km'] == 0) & (df['trip_duration_minutes'] > 10))
        ]

    # --- extra time fields useful for analysis ---
    if 'start_time' in df:
        df['start_hour']    = df['start_time'].dt.hour
        df['start_weekday'] = df['start_time'].dt.day_name()
        df['is_weekend']    = df['start_time'].dt.weekday >= 5
        df['rush_hour']     = df['start_hour'].between(7,9) | df['start_hour'].between(16,19)
        df['start_date']    = df['start_time'].dt.date

    # lat/lon deltas
    if {'start_latitude','end_latitude'}.issubset(df.columns) and 'latitude_change' not in df:
        df['latitude_change']  = df['end_latitude']  - df['start_latitude']
    if {'start_longitude','end_longitude'}.issubset(df.columns) and 'longitude_change' not in df:
        df['longitude_change'] = df['end_longitude'] - df['start_longitude']

    return df

# ==== 2) Weather cleaning ====
def clean_weather(df_raw: pd.DataFrame) -> pd.DataFrame:
    df = df_raw.copy()

    # drop columns that are completely null (PGTM, TSUN)
    all_null_cols = df.columns[df.isna().all()]
    df = df.drop(columns=all_null_cols)

    # parse date
    if 'DATE' in df.columns:
        df['DATE'] = pd.to_datetime(df['DATE'])

    # rename columns to descriptive names better for analysis
    rename_map = {
        'STATION': 'station',
        'NAME': 'name',
        'DATE': 'date',
        'AWND': 'average_daily_wind_speed_mph',
        'PRCP': 'precipitation_in',
        'SNOW': 'snowfall_in',
        'SNWD': 'snow_depth_in',
        'TAVG': 'average_temp_f',
        'TMAX': 'max_temp_f',
        'TMIN': 'min_temp_f',
        'WDF2': 'wind_direction_fastest_2_min_degrees',
        'WSF2': 'wind_speed_fastest_2_min_mph',
        'WSF5': 'wind_speed_fastest_5_sec_mph',
    }
    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})

    return df

# --- run custom functions to clean datasets ---
citibike = clean_citibike(citibike_raw)
weather  = clean_weather(weather_raw)

# quick sanity check
display(citibike.head())
display(weather.head())

# --- saving cleaned datasets to local environment ---
citibike.to_csv('citibike_cleaned.csv', index=False)
weather.to_csv('weather_cleaned.csv', index=False)

# downloading files to local computer
from google.colab import files
files.download('citibike_cleaned.csv')
files.download('weather_cleaned.csv')